# Importar bibliotecas necessárias
import pandas as pd
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns

# Importa os dados iniciais
entrada = pd.read_excel("Entrada_simples.xlsx", sheet_name="entrada")
entrada = pd.read_excel("Entrada_simples_v2.xlsx", sheet_name="entrada") # Base 1 (mercado 1 s/ tarifa e horário)
entrada = pd.read_excel("Entrada_simples_v2.xlsx", sheet_name="entrada2") # Base 2 (mercado 1 + 2)

# Remover todas as linhas com valores NA
dado_limpo = entrada.dropna()

# Dicionário com a classificação que você deseja
category_mapping = {
    "Y": 0,
    "B": 1,
    "H": 2,
    "K": 3,
    "M": 4,
    "L": 5,
    "V": 6,
    "X": 7,
    "S": 8,
    "N": 9,
    "Q": 10,
    "O": 11,
    "G": 12,
    "TC": 99
}

# Colunas que precisam seguir essa classificação
categorical_cols = ["CM0", "CM1", "CM2", "CM3", "match_min", "CL"]

# Aplicar o mapeamento nas colunas especificadas
for col in categorical_cols:
    dado_limpo[col] = dado_limpo[col].map(category_mapping)

# Dicionários com a classificação para as novas colunas
season_mapping = {
    "HIGH": 1,
    "LOW": 2,
    "CARNAVAL": 3
}

clstr_mapping = {
    "MF": 4,
    "FO": 3,
    "MO": 2,
    "FR": 1
}

fluxo_mapping = {
    "Fluxo": 2,
    "CF": 1,
    "indefinido": 0
}

# Aplicar o mapeamento nas colunas especificadas
dado_limpo["Season"] = dado_limpo["Season"].map(season_mapping)
dado_limpo["CLSTR"] = dado_limpo["CLSTR"].map(clstr_mapping)
dado_limpo["Fluxo"] = dado_limpo["Fluxo"].map(fluxo_mapping)    


###############################################################################

# Separar features e variÃ¡vel alvo
# BKP    X = dado_limpo.drop(columns=["CM0", "ORDEM", "TIME", "TIME.1"])  # Features
X = dado_limpo.drop(columns=["CM0"])  # Features
y = dado_limpo["CM0"]  # VariÃ¡vel alvo

# Dividir os dados em treino e teste
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=123, stratify=y)

# Hiperparâmetros Random Forest
modelo_rf = RandomForestClassifier(
    n_estimators=500, 
    random_state=123, 
    max_depth=25, 
    min_samples_split=4, 
    max_features='sqrt',
    n_jobs=-1
)


modelo_rf.fit(X_train, y_train)

# Gerar previsÃµes
previsoes = modelo_rf.predict(X_test)

###############################################################################
# K-Fold Test

from sklearn.model_selection import StratifiedKFold, cross_val_score
import numpy as np

# Definir o StratifiedKFold cross-validator
skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=123)

# Avaliar o modelo com K-fold Cross Validation usando estratificação
scores = cross_val_score(modelo_rf, X, y, cv=skf, scoring='accuracy')

# Exibir as pontuações e a média
print("Scores em cada fold: ", scores)
print("Acurácia média: ", np.mean(scores))

####################################################################################
# AVALIAÃÃO DO MODELO #
# MATRIZ DE CONFUSÃO #

# Definir as classes de 0 a 12
classes = list(range(13))

# Gerar a matriz de confusÃ£o
matriz_confusao = confusion_matrix(y_test, previsoes, labels=classes)

# Verificar a matriz de confusÃ£o para garantir que esteja correta
print(matriz_confusao)

# Criar DataFrame a partir da matriz de confusÃ£o para plottar o grÃ¡fico
conf_df = pd.DataFrame(matriz_confusao, index=classes, columns=classes)

# Plotar o heatmap com cores e anotaÃ§Ãµes ajustadas
plt.figure(figsize=(10, 8))
sns.heatmap(conf_df, annot=True, fmt='d', cmap='Blues', cbar=False, 
            annot_kws={"color": "black"})  # Cor das anotaÃ§Ãµes

# Ajustar os tÃ­tulos e rÃ³tulos
plt.title('Matriz de ConfusÃ£o', fontsize=16)
plt.xlabel('Previsto', fontsize=12)
plt.ylabel('Observado', fontsize=12)
plt.xticks(rotation=45)
plt.yticks(rotation=0)

# Exibir o grÃ¡fico
plt.tight_layout()
plt.show()

####################################################################################

from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report
import numpy as np

# AvaliaÃ§Ã£o do modelo

# AcurÃ¡cia
acuracia = accuracy_score(y_test, previsoes)
print(f"AcurÃ¡cia: {acuracia:.4f}")

# Contagem de instâncias por classe
from collections import Counter
pesos = np.array(list(Counter(y_test).values()))

# PrecisÃ£o, Sensibilidade (Recall) e F1-Score para cada classe
precisao = precision_score(y_test, previsoes, average=None)
sensibilidade = recall_score(y_test, previsoes, average=None)
f1_scores = f1_score(y_test, previsoes, average=None)

# Exibir as mÃ©tricas para cada classe
for i, classe in enumerate(classes):
    print(f"\nClasse: {classe}")
    print(f"PrecisÃ£o: {precisao[i]:.4f}")
    print(f"Sensibilidade (Recall): {sensibilidade[i]:.4f}")
    print(f"F1-Score: {f1_scores[i]:.4f}")
    
    # Cálculo da média ponderada para Precisão, Sensibilidade e F1-Score
    precisao_ponderada = np.average(precisao, weights=pesos)
    sensibilidade_ponderada = np.average(sensibilidade, weights=pesos)
    f1_score_ponderado = np.average(f1_scores, weights=pesos)    
        
    print("\nMédias Ponderadas:")
    print(f"Precisão Ponderada: {precisao_ponderada:.4f}")
    print(f"Sensibilidade Ponderada: {sensibilidade_ponderada:.4f}")
    print(f"F1-Score Ponderado: {f1_score_ponderado:.4f}") 

# RelatÃ³rio de classificaÃ§Ã£o completo
print("\nRelatÃ³rio de ClassificaÃ§Ã£o Completo:\n")
print(classification_report(y_test, previsoes, target_names=[str(c) for c in classes]))

# Para visualizar a precisÃ£o, recall e F1-score de maneira tabular
resultados_parametricos = pd.DataFrame({
    'Classe': classes,
    'Precisao': precisao,
    'Sensibilidade (Recall)': sensibilidade,
    'F1-Score': f1_scores
})

print("\nTabela Resumida de Resultados:\n")
print(resultados_parametricos)


####################################################################################

# TESTE CGR

# Importa os dados iniciais CGR
entrada_CGR = pd.read_excel("Entrada_simples_v2.xlsx", sheet_name="entrada4")

# Remover todas as linhas com valores NA
dado_limpoCGR = entrada_CGR.dropna()

# Nova base de teste (ou nova base)
for col in categorical_cols:
    dado_limpoCGR[col] = dado_limpoCGR[col].map(category_mapping) # Transformar os dados de teste com o encoder do treino


# Aplicar o mapeamento nas colunas especificadas
dado_limpoCGR["Season"] = dado_limpoCGR["Season"].map(season_mapping)
dado_limpoCGR["CLSTR"] = dado_limpoCGR["CLSTR"].map(clstr_mapping)
dado_limpoCGR["Fluxo"] = dado_limpoCGR["Fluxo"].map(fluxo_mapping)   


X_CGR = dado_limpoCGR.drop(columns=["CM0"])  # Features
y_CGR = dado_limpoCGR["CM0"]  # VariÃ¡vel alvo

# Alinhar colunas entre o modelo treinado (X_train) e a nova base (X_CGR)
X_CGR = X_CGR.reindex(columns=X_train.columns, fill_value=0)


# Gerar previsÃµes CGR
previsoes_CGR = modelo_rf.predict(X_CGR)

# Gerar a matriz de confusÃ£o
matriz_confusaoCGR = confusion_matrix(y_CGR, previsoes_CGR, labels=classes)

# Verificar a matriz de confusÃ£o para garantir que esteja correta
print(matriz_confusaoCGR)

# AcurÃ¡cia
acuraciaCGR = accuracy_score(y_CGR, previsoes_CGR)
print(f"AcurÃ¡cia: {acuraciaCGR:.4f}")

# Criar DataFrame a partir da matriz de confusÃ£o para plottar o grÃ¡fico
conf_dfCGR = pd.DataFrame(matriz_confusaoCGR, index=classes, columns=classes)

# Plotar o heatmap com cores e anotaÃ§Ãµes ajustadas
plt.figure(figsize=(10, 8))
sns.heatmap(conf_dfCGR, annot=True, fmt='d', cmap='Blues', cbar=False, 
            annot_kws={"color": "black"})  # Cor das anotaÃ§Ãµes

import numpy as np  # Importar NumPy


# Inicializar uma variÃ¡vel para a acurÃ¡cia ponderada
weighted_accuracy = 0
total_instances = np.sum(matriz_confusaoCGR)

for i in range(len(matriz_confusaoCGR)):
    for j in range(len(matriz_confusaoCGR)):
        # Ponderar o acerto completo com peso 1
        if i == j:
            weighted_accuracy += matriz_confusaoCGR[i, j]
        # Ponderar erros adjacentes com peso 0.5
        elif abs(i - j) == 1:
            weighted_accuracy += 0.5 * matriz_confusaoCGR[i, j]

weighted_accuracy /= total_instances

print(f"AcurÃ¡cia ponderada: {weighted_accuracy:.4f}")

###########################################################################
###########################################################################
# ACURÃCIA POR AGRUPAMENTO CGR

import numpy as np
from sklearn.metrics import accuracy_score

# DicionÃ¡rio de mapeamento reverso (inteiros para classes)
mapeamento_reverso = {
    0: 'Y', 1: 'B', 2: 'H', 3: 'K', 4: 'M', 5: 'L', 6: 'V', 
    7: 'X', 8: 'S', 9: 'N', 10: 'Q', 11: 'O', 12: 'G'
}

# FunÃ§Ã£o para aplicar o mapeamento reverso
def reverter_para_classes(numeros):
    return [mapeamento_reverso[numero] for numero in numeros]

# Suponha que 'y_test' e 'previsoes' sejam arrays de nÃºmeros inteiros (0, 1, 2, etc.)
# Reverter os inteiros para as classes originais
y_test_classes_CGR = reverter_para_classes(y_CGR)  # Classes reais
previsoes_classes_CGR = reverter_para_classes(previsoes_CGR)  # PrevisÃµes

# Definir os grupos de mix
mix_high = ['Y', 'B', 'H', 'K']
mix_mid = ['M', 'L', 'V', 'X', 'S', 'N']
mix_low = ['Q', 'O', 'G']

# FunÃ§Ã£o para mapear as classes para seus respectivos grupos
def map_to_mix_group(label):
    if label in mix_high:
        return 'MIX HIGH'
    elif label in mix_mid:
        return 'MIX MID'
    elif label in mix_low:
        return 'MIX LOW'
    else:
        return 'UNKNOWN'  # Caso tenha algum valor inesperado

# Agora, aplicar o mapeamento para os grupos de mix nas classes reais e previstas
y_test_mix_group_cgr = [map_to_mix_group(label) for label in y_test_classes_CGR]
previsoes_mix_group_cgr = [map_to_mix_group(label) for label in previsoes_classes_CGR]

# Calcular a acurÃ¡cia total por grupo de mix
acuracia_mix_cgr = accuracy_score(y_test_mix_group_cgr, previsoes_mix_group_cgr)
print(f"AcurÃ¡cia por grupo de mix: {acuracia_mix:.4f}")

# Calcular a acurÃ¡cia separada para cada grupo (MIX HIGH, MIX MID, MIX LOW)
for mix_group in ['MIX HIGH', 'MIX MID', 'MIX LOW']:
    y_test_group_cgr = [1 if label == mix_group else 0 for label in y_test_mix_group_cgr]
    previsoes_group_cgr = [1 if label == mix_group else 0 for label in previsoes_mix_group_cgr]
    
    acuracia_grupo = accuracy_score(y_test_group_cgr, previsoes_group_cgr)
    print(f"AcurÃ¡cia para {mix_group}: {acuracia_grupo:.4f}")
    
 #############
# TESTE Comum   agrupamento 
    
 import numpy as np
 from sklearn.metrics import accuracy_score

 # DicionÃ¡rio de mapeamento reverso (inteiros para classes)
 mapeamento_reverso = {
     0: 'Y', 1: 'B', 2: 'H', 3: 'K', 4: 'M', 5: 'L', 6: 'V', 
     7: 'X', 8: 'S', 9: 'N', 10: 'Q', 11: 'O', 12: 'G'
 }

 # FunÃ§Ã£o para aplicar o mapeamento reverso
 def reverter_para_classes(numeros):
     return [mapeamento_reverso[numero] for numero in numeros]

 # Suponha que 'y_test' e 'previsoes' sejam arrays de nÃºmeros inteiros (0, 1, 2, etc.)
 # Reverter os inteiros para as classes originais
 y_test_classes = reverter_para_classes(y_test)  # Classes reais
 previsoes_classes = reverter_para_classes(previsoes)  # PrevisÃµes

 # Definir os grupos de mix
 mix_high = ['Y', 'B', 'H', 'K']
 mix_mid = ['M', 'L', 'V', 'X', 'S', 'N']
 mix_low = ['Q', 'O', 'G']

 # FunÃ§Ã£o para mapear as classes para seus respectivos grupos
 def map_to_mix_group(label):
     if label in mix_high:
         return 'MIX HIGH'
     elif label in mix_mid:
         return 'MIX MID'
     elif label in mix_low:
         return 'MIX LOW'
     else:
         return 'UNKNOWN'  # Caso tenha algum valor inesperado

 # Agora, aplicar o mapeamento para os grupos de mix nas classes reais e previstas
 y_test_mix_group = [map_to_mix_group(label) for label in y_test_classes]
 previsoes_mix_group = [map_to_mix_group(label) for label in previsoes_classes]

 # Calcular a acurÃ¡cia total por grupo de mix
 acuracia_mix = accuracy_score(y_test_mix_group, previsoes_mix_group)
 print(f"AcurÃ¡cia por grupo de mix: {acuracia_mix:.4f}")

 # Calcular a acurÃ¡cia separada para cada grupo (MIX HIGH, MIX MID, MIX LOW)
 for mix_group in ['MIX HIGH', 'MIX MID', 'MIX LOW']:
     y_test_group = [1 if label == mix_group else 0 for label in y_test_mix_group]
     previsoes_group = [1 if label == mix_group else 0 for label in previsoes_mix_group]
     
     acuracia_grupo = accuracy_score(y_test_group, previsoes_group)
     print(f"AcurÃ¡cia para {mix_group}: {acuracia_grupo:.4f}")   
     
     
############################

X_test.to_excel("X_test_export.xlsx", index=False)  # O index=False remove o Ã­ndice do arquivo
y_test.to_excel("y_test_export.xlsx", index=False)  # O index=False remove o Ã­ndice do arquivo
previsoes_series.to_excel("previsoes_testexport.xlsx", index=False)  # O index=False remove o Ã­ndice do arquivo 

previsoes_series = pd.Series(previsoes) 
